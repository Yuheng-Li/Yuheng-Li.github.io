
<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-61135638-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-61135638-2');
  </script>

  <title>Yuheng Li</title>

  <meta name="author" content="Yuheng Li">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta property="og:description" content="Personal webpage of Yuheng Li." />
    <link rel="stylesheet" href="jemdoc.css" type="text/css" />
    <!-- <link rel="icon" type="image/png" href="./images/duck2.png" /> -->
    <link rel="icon" type="image/png" href="./images/adobe-logo.png" />
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <style>
        #profile_photo {
            max-width: 300px;
            transition: all 0.3s ease;
        }
        #profile_photo:hover {
            content: url('images/yuheng-and-mam.jpg');
        }
    </style>
</head>

<body>
  <div class="container" style="max-width: 900px;">
    <div class="section">
      <!-- <div id="profile" class="box" style="width: 100%"> -->
<!--       <div id="profile" class="box" style="width: 750px;">
        <p style="text-align:center">
          <name>Yuheng Li</name>
        </p>
        <p> -->
          <!-- Hi, I am a computer science Ph.D. student at University of Wisconsin-Madison, advised by <a href="https://pages.cs.wisc.edu/~yongjaelee/">Prof. Yong Jae Lee</a>. Generally, I am interested in <b>controllable and multimodal image generation and manipulation.</b> -->
          <!-- Hi! I am a research scientist at <a href= -->
<!--         "https://research.adobe.com/"> Adobe Research</a>.
        <br>
        Before joining Adobe, I got my PhD in Computer Science from University of Wisconsin-Madison in 2024, under the supervision <a href="https://pages.cs.wisc.edu/~yongjaelee/">Prof. Yong Jae Lee</a>.
        <br>
        <br>

        Generally, I am interested in <b>controllable and multimodal image generation and manipulation</b>.
        <br>
        <font color="red"> Feel free to contact me for collaboration.</font>  -->
          <!-- <br> -->
          <!-- <br> -->
          <!-- <font color="red"> I will graduate in 2024 summer and will join Adobe Research, feel free to contact me for collaboration.</font>  -->
<!--         </p>
        <p style="text-align:center">
          <a href="mailto:li2464@wisc.edu">Email</a> &nbsp;/&nbsp;
          <a href="files/CV.pdf">CV</a> &nbsp;/&nbsp;
          <a href="https://scholar.google.com/citations?user=ZphbAXEAAAAJ&hl=en">Google Scholar</a> 
        </p>
      </div>
      <div class="box" style="width: 180px; float: left; padding: 30px 0 0 0;"> -->
        <!-- <img id="profile_photo" alt="profile photo" src="images/photo.jpeg"> -->
        <!-- <img id="profile_photo" alt="profile photo" src="images/yosemite.jpg"> -->
        <!-- <img id="profile_photo" alt="profile photo" src="images/cvpr2024.jpg"> -->
      <!-- </div> -->
    <!-- </div> -->
    <center>
    <table style="max-width: 900px;">
      <tr>
        <td>
          <div class="section">
            <!-- <div id="profile" class="box"> -->
              <p style="text-align:center">
                <name>Yuheng Li</name>
              </p>
              <p>
                Hi! I am a research scientist at <a href="https://research.adobe.com/">Adobe Research</a>.
                <br>
                Before joining Adobe, I got my PhD in Computer Science from University of Wisconsin-Madison in 2024, under the supervision <a href="https://pages.cs.wisc.edu/~yongjaelee/">Prof. Yong Jae Lee</a>.
                <br>
                <br>
                Generally, I am interested in <b>controllable & multimodal image generation/ manipulation</b>.
                <br>
                <font color="red">Feel free to contact me for collaboration.</font>
                <br>
              </p>
              <!-- <i><p style="font-size: 70%;text-align: right;">(Photo credit: <a href="https://en.wikipedia.org/wiki/Bucky_Badger" style="font-size: inherit;">Bucky</a>, taken by <a href="https://anhddo.github.io" target="blank" style="font-size: inherit;">Anh Do</a>, at <a href='https://goo.gl/maps/N85trQSczcrS32Fi6' style="font-size: inherit;">Henry Vilas Zoo</a> (2022).&nbsp&nbsp&nbsp&nbsp&nbsp</p></i> -->


              <p style="text-align:center">
                <a href="mailto:li2464@wisc.edu">Email</a> &nbsp;/&nbsp;
                <a href="files/CV.pdf">CV</a> &nbsp;/&nbsp;
                <a href="https://scholar.google.com/citations?user=ZphbAXEAAAAJ&hl=en">Google Scholar</a>
              </p>
              <!-- <p style="font-size:80%;color:#A9A9A9"><i>(Photo credit: The "silly" cat in the photo is Mam -- <a href="https://thaoshibe.github.io/" style="font-size:95%">Thao</a>'s cat. He appears in 02 of my papers. Can you spot him? ;)) -->
              </p>
            </i>
            <!-- </div> -->
          </div>
        </td>
        <td>
            <!-- <img id="profile_photo" alt="profile photo" src="images/yosemite.jpg" style='max-width: 300px;'> -->
            <!-- <img id="profile_photo" alt="profile photo" src="images/yosemite3.jpg"> -->
            <img src="images/yosemite3.jpg" style="max-width: 300px;">
            <!-- <img src="images/yosemite3.jpg" 
     onmouseover="this.src='yosemite3.jpg'" 
     onmouseout="this.src='images/yosemite3.jpg'" 
     style="max-width:300px;">
            <br> -->

          
        </td>
      </tr>
    </table>
    </div>
    <!-- <br> -->
    <!-- <br> -->
    <br>
  </center>
    <div class="section">
      <heading>Research</heading>
      <br>
      <br>
      <!-- <br> -->

      <div class="container">
        <div class="box left">
          <a href='https://sichengmo.github.io/XFusion/'>
          <img src='./images/xfusion.png'></a>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2504.20996" target="_blank">
              <papertitle>X-Fusion: Introducing New Modality to Frozen Large Language Models</papertitle>
          </a>
          <br>
          Sicheng Mo, Thao Nguyen, Xun Huang, Siddharth Srinivasan Iyer, Yijun Li, Yuchen Liu, Abhishek Tandon, Eli Shechtman, Krishna Kumar Singh, Yong Jae Lee, Bolei Zhou, <strong>Yuheng Li</strong>
          <br>
          <em>IEEE International Conference on Computer Vision</em>, (<strong>ICCV</strong>), 2025
          <br>
          <i style="color:#ee2400">üèÜ Best paper at CVPR 2025 Workshop: "Transformers for Vision (T4V)</i>
          <br>
          [<a href="https://sichengmo.github.io/XFusion/" target=&ldquo;blank&rdquo;>ProjectPage</a>, <a href="https://sichengmo.github.io/XFusion/" target=&ldquo;blank&rdquo;>Code</a>, <a href="https://arxiv.org/abs/2504.20996" target=&ldquo;blank&rdquo;>Paper</a>]
          <p></p>
          <br>
        </div>
      </div>
      <div class="clear"></div>

      <div class="container">
        <div class="box left">
          <a href='https://thaoshibe.github.io/YoChameleon/'>
          <img src='./images/yochameleon.png'></a>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2406.09400" target="_blank">
              <papertitle>Yo'Chameleon: Personalized Vision and Language Generation</papertitle>
          </a>
          <br>
          Thao Nguyen, Krishna Kumar Singh, Jing Shi, Trung Bui, Yong Jae Lee, <strong>Yuheng Li</strong>
          <br>
          <em>Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2025
          <br>
          [<a href="https://thaoshibe.github.io/YoChameleon/" target=&ldquo;blank&rdquo;>ProjectPage</a>, <a href="https://github.com/thaoshibe/YoChameleon" target=&ldquo;blank&rdquo;>Code</a>, <a href="https://arxiv.org/abs/2504.20998" target=&ldquo;blank&rdquo;>Paper</a>]
          <p></p>
        </div>
      </div>
      <div class="clear"></div>

      <div class="container">
        <div class="box left">
          <a href='https://glitchinthematrix.github.io/vins/'>
          <img src='https://krsingh.cs.ucdavis.edu/krishna_files/paper_images/vins_teaser.png'></a>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2503.17539" target="_blank">
              <papertitle>Generating, Fast and Slow: Scalable Parallel Video Generation with Video Interface Networks</papertitle>
          </a>
          <br>
          Bhishma Dedhia, David Bourgin, Krishna Kumar Singh, <strong>Yuheng Li</strong>, Yan Kang, Zhan Xu, Niraj K. Jha, Yuchen Liu
          <br>
          arXiv, 2025
          <br>
          [<a href="https://glitchinthematrix.github.io/vins/" target=&ldquo;blank&rdquo;>ProjectPage</a>,<a href="https://arxiv.org/abs/2503.17539" target=&ldquo;blank&rdquo;>Paper</a>]
          <p></p>
        </div>
      </div>
      <div class="clear"></div>
<!--       <div class="container">
        <div class="box left">
          <a href='https://thaoshibe.github.io/YoChameleon/'>
          <img src='./images/yochameleon.png'></a>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2406.09400" target="_blank">
              <papertitle>Interpolating Video-LLMs: Toward Longer-sequence LMMs in a Training-free Manner</papertitle>
          </a>
          <br>
          Yuzhang Shang, Bingxin Xu, Weitai Kang, Mu Cai, <strong>Yuheng Li</strong>, Zehao Wen, Zhen Dong, Kurt Keutzer, Yong Jae Lee, Yan Yan
          <br>
          arXiv, 2024
          <br>
          [<a href="https://arxiv.org/abs/2409.12963" target=&ldquo;blank&rdquo;>Paper</a>]
          <p></p>
        </div>
      </div>
      <div class="clear"></div> -->

      <div class="container">
        <div class="box left">
          <a href='https://thaoshibe.github.io/YoLLaVA/'>
          <img src='./images/yollava.png'></a>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2406.09400" target="_blank">
              <papertitle>Yo'LLaVA: Your Personalized Language and Vision Assistant</papertitle>
          </a>
          <br>
          Thao Nguyen, Haotian Liu, <strong>Yuheng Li</strong>, Mu Cai, Utkarsh Ojha, Yong Jae Lee
          <br>
          <em>Neural Information Processing Systems</em> (<strong>NeurIPS</strong>), 2024
          <br>
          [<a href="https://thaoshibe.github.io/YoLLaVA/" target=&ldquo;blank&rdquo;>ProjectPage</a>, <a href="https://github.com/WisconsinAIVision/YoLLaVA" target=&ldquo;blank&rdquo;>Code</a>, <a href="https://arxiv.org/abs/2406.09400" target=&ldquo;blank&rdquo;>Paper</a>]
          <p></p>
          <!-- <br> -->
        </div>
      </div>
      <div class="clear"></div>




      <div class="container">
        <div class="box left">
          <img src='https://pages.cs.wisc.edu/~yongjaelee/IMAGES/llava_v15.jpeg'>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2310.03744" target="_blank">
              <papertitle>Improved Baselines with Visual Instruction Tuning (LLaVA-1.5)</papertitle>
          </a>
          <br>
          Haotian Liu, Chunyuan Li, <strong>Yuheng Li</strong>, Yong Jae Lee
          <br>
          <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2024
          <br>
          [<a href="https://llava-vl.github.io/" target=&ldquo;blank&rdquo;>ProjectPage</a>, <a href="https://github.com/haotian-liu/LLaVA" target=&ldquo;blank&rdquo;>Code</a>, <a href="https://arxiv.org/abs/2310.03744" target=&ldquo;blank&rdquo;>Paper</a>]
          <p></p>
        </div>
      </div>
      <div class="clear"></div>




      <div class="container">
        <div class="box left">
          <img src='https://pages.cs.wisc.edu/~yongjaelee/IMAGES/edit-one-for-all.jpg'>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2401.10219" target="_blank">
              <papertitle>Edit One for All: Interactive Batch Image Editing</papertitle>
          </a>
          <br>
          Thao Nguyen, Utkarsh Ojha, <strong>Yuheng Li</strong>, Haotian Liu, Yong Jae Lee

          <br>
          <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2024
          <br>
          [<a href="https://thaoshibe.github.io/edit-one-for-all" target=&ldquo;blank&rdquo;>ProjectPage</a>, <a href="https://github.com/thaoshibe/edit-one-for-all" target=&ldquo;blank&rdquo;>Code</a>, <a href="https://arxiv.org/abs/2401.10219" target=&ldquo;blank&rdquo;>Paper</a>]
          <p></p>
        </div>
      </div>
      <div class="clear"></div>


      <div class="container">
        <div class="box left">
          <img src='images/pacgen.png'>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2306.17154" target="_blank">
              <papertitle>Generate Anything Anywhere in Any Scene </papertitle>
          </a>
          <br>
          <strong>Yuheng Li</strong>, Haotian Liu, Yangming Wen, Yong Jae Lee
          <br>
          <em>arxiv</em>, 2023
          <p></p>
        </div>
      </div>
      <div class="clear"></div>



      <div class="container">
        <div class="box left">
          <img src='images/svg_llm.png'>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2306.06094" target="_blank">
              <papertitle>Leveraging Large Language Models for Scalable Vector Graphics-Driven Image Understanding</papertitle>
          </a>
          <br>
          Mu Cai*, Zeyi Huang*, <strong>Yuheng Li</strong>, Haohan Wang, and Yong Jae Lee
          <br>
          (*equal contribution)
          <br>
          <em>IEEE Winter Conference on Applications of Computer Vision (<b>WACV</b>), 2025</em>, 2023
          <p></p>
        </div>
      </div>
      
      <div class="clear"></div>


      <div class="container">
        <div class="box left">
          <img src='images/vii.png'>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2307.14331" target="_blank">
              <papertitle>Visual Instruction Inversion: Image Editing via Visual Prompting</papertitle>
          </a>
          <br>
          Thao Nguyen, <strong>Yuheng Li</strong>, Utkarsh Ojha, Yong Jae Lee
          <br>
          <em>Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2023
          <br>
          [<a href="https://thaoshibe.github.io/visii" target=&ldquo;blank&rdquo;>ProjectPage</a>, <a href="https://github.com/thaoshibe/visii" target=&ldquo;blank&rdquo;>Code</a>, <a href="https://arxiv.org/abs/2307.14331" target=&ldquo;blank&rdquo;>Paper</a>]
          <p></p>
        </div>
      </div>
      
      
      <div class="clear"></div>




      <div class="container">
        <div class="box left">
          <img src='images/kd.png'>
        </div>
        <div class="box right">
          <a href="#" target="_blank">
              <papertitle>What Knowledge Gets Distilled in Knowledge Distillation?</papertitle>
          </a>
          <br>
          Utkarsh Ojha*, <strong>Yuheng Li*</strong>, Anirudh Sundara Rajan*, Yingyu Liang, Yong Jae Lee
          <br>
          (*equal contribution)
          <br>
          <em>Neural Information Processing Systems</em> (<b>NeurIPS</b>), 2023
          <p></p>
        </div>
      </div>
      <div class="clear"></div>

 

      
      <div class="container">
        <div class="box left">
          <img src='images/gligen.png'>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2301.07093" target="_blank">
              <papertitle>GLIGEN: Open-Set Grounded Text-to-Image Generation </papertitle>
          </a>
          <br>
          <strong>Yuheng Li</strong>,  Haotian Liu, Qingyang Wu, Fangzhou Mu, Jianwei Yang, Jianfeng Gao, Chunyuan Li*, Yong Jae Lee*
          <br>
          (*equal advising)
          <br>
          <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2023
          <br>
          [<a href="https://arxiv.org/abs/2301.07093" target="_blank">arXiv</a>] [<a href="https://github.com/gligen/GLIGEN" target="_blank">code</a>] [<a href="https://gligen.github.io/" target="_blank">Project Page</a>] [<a href="https://huggingface.co/spaces/gligen/demo" target="_blank">Demo</a>]  [<a href="https://www.youtube.com/watch?v=-MCkU7IAGKs&ab_channel=ComputerVisionintheWild%28CVinW%29" target="_blank">Youtube</a>]
          <br>
          <p></p>
        </div>
      </div>
      
      
      
      <div class="clear"></div>
      
      
      <div class="container">
        <div class="box left">
          <img src='images/fake_detection.png'>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2302.10174" target="_blank">
              <papertitle>Towards Universal Fake Image Detectors that Generalize Across Generative Models </papertitle>
          </a>
          <br>
          Utkarsh Ojha*, <strong>Yuheng Li*</strong>, Yong Jae Lee
          <br>
          (*equal contribution)
          <br>
          <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2023
          <p></p>
        </div>
      </div>



      <div class="clear"></div>



      <div class="container">
        <div class="box left">
          <img src='images/anti-aliasing.gif'>
        </div>
        <div class="box right">
          <a href="#" target="_blank">
              <papertitle>Delving Deeper into Anti-aliasing in ConvNets</papertitle>
          </a>
          <br>
          Xueyan Zou, Fanyi Xiao, Zhiding Yu, <strong>Yuheng Li</strong>, and Yong Jae Lee
          <br>
          <em>International Journal of Computer Vision</em> (<strong>IJCV</strong>), 2022
          <p></p>
        </div>
      </div>




      <div class="clear"></div>



      <div class="container">
        <div class="box left">
          <img src='images/contrasfill.png'>
        </div>
        <div class="box right">
          <a href="#" target="_blank">
              <papertitle>Contrastive Learning for Diverse Disentangled Foreground Generation</papertitle>
          </a>
          <br>
          <strong>Yuheng Li</strong>, Yijun Li, Jingwan Lu, Eli Shechtman, Yong Jae Lee, Krishna Kumar Singh
          <br>
          <em>Proceedings of the European Conference on Computer Vision</em> (<strong>ECCV</strong>), 2022
          <p></p>
        </div>
      </div>



      <div class="clear"></div>



      <div class="container">
        <div class="box left">
          <img src='images/giraffehd.png'>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2203.14954" target="_blank">
              <papertitle>GIRAFFE HD: A High-Resolution 3D-aware Generative Model</papertitle>
          </a>
          <br>
          Yang Xue, <strong>Yuheng Li</strong>, Krishna Kumar Singh, Yong Jae Lee
          <br>
          <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2022
          <br>
          [<a href="https://arxiv.org/abs/2203.14954" target="_blank">arXiv</a>] [<a href="https://github.com/AustinXY/GIRAFFEHD" target="_blank">code</a>]
          <br>
          <p></p>
        </div>
      </div>



      <div class="clear"></div>



      <div class="container">
        <div class="box left">
          <img src='images/collageGAN.png'>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/2110.04281v1" target="_blank">
              <papertitle>Collaging Class-specific GANs for Semantic Image Synthesis</papertitle>
          </a>
          <br>
          <strong>Yuheng Li</strong>, Yijun Li, Jingwan Lu, Eli Shechtman, Yong Jae Lee, Krishna Kumar Singh
          <br>
          <em>IEEE International Conference on Computer Vision</em> (<strong>ICCV</strong>), 2021
          <br>
          [<a href="https://arxiv.org/abs/2110.04281v1" target="_blank">arXiv</a>] [<a href="https://yuheng-li.github.io/CollageGAN/" target="_blank">project</a>]
          <br>
          <p></p>
        </div>
      </div>



      <div class="clear"></div>



      <div class="container">
        <div class="box left">
          <img src='images/partgan.png'>
        </div>
        <div class="box right">
          <a href="https://www.bmvc2021-virtualconference.com/conference/papers/paper_0057.html" target="_blank">
              <papertitle>PartGAN: Unsupervised Part Decomposition for Image Generation and Segmentation </papertitle>
          </a>
          <br>
          <strong>Yuheng Li</strong>,  Krishna Kumar Singh, Yong Jae Lee 
          <br>
          <em>British Machine Vision Conference</em> (<strong>BMVC</strong>), 2021
          <br>
          <p></p>
        </div>
      </div>



      <div class="clear"></div> 



      <div class="container">
        <div class="box left">
          <img src='images/MixNMatch.png'>
        </div>
        <div class="box right">
          <a href="https://arxiv.org/abs/1911.11758" target="_blank">
              <papertitle>MixNMatch: Multifactor Disentanglement and Encoding for Conditional Image Generation </papertitle>
          </a>
          <br>
          <strong>Yuheng Li</strong>,  Krishna Kumar Singh, Utkarsh Ojha, Yong Jae Lee 
          <br>
          <em>IEEE Conference on Computer Vision and Pattern Recognition</em> (<strong>CVPR</strong>), 2020
          <br>
          [<a href="https://arxiv.org/abs/1911.11758" target="_blank">arXiv</a>] [<a href="https://github.com/Yuheng-Li/MixNMatch" target="_blank">code</a>]
          <br>
          <p></p>
        </div>
      </div>

    </div>
  </div>
  <br>
<div class="clear"></div> 
<!-- <hr> -->
<div class="container">
  <center>
  <div id="footer-text">You've reached the end.
  </div>
</center>
</div>
</body>
</html>
